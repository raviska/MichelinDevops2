{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad717a7",
   "metadata": {},
   "source": [
    "# Deploy model as a webservice on Azure Kubernetes Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f7693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.33.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import azureml.core\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f9fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlops-workspace\n",
      "learn_mlops_2\n",
      "centralus\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d80b7e",
   "metadata": {},
   "source": [
    "# Deploy model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7a760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "from azureml.core.model import Model\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def preprocess_data(data):\n",
    "    corpus=[]\n",
    "    for i in data:\n",
    "        mess=re.sub(\"[^a-zA-Z0-9]\",\" \",i)\n",
    "        mess=mess.lower().split()\n",
    "        mess=[lemmatizer.lemmatize(word) for word in mess if word not in stopwords.words(\"english\")]\n",
    "        mess=\" \".join(mess)\n",
    "        corpus.append(mess)\n",
    "    return corpus    \n",
    "\n",
    "\n",
    "def init():\n",
    "    global count_vect,rf_model\n",
    "    \n",
    "    count_vect_path=Model.get_model_path('NLP_Count_Vectorizer')\n",
    "    count_vect= joblib.load(count_vect_path)\n",
    "    \n",
    "    rf_model_path=Model.get_model_path('NLP_RF_Model')\n",
    "    rf_model=joblib.load(rf_model_path)\n",
    "    \n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        corpus=preprocess_data(data[0])\n",
    "        count_test=count_vect.transform(corpus)\n",
    "        prediction=rf_model.predict(count_test)\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return json.dumps({\"result\": prediction.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        # return error message back to the client\n",
    "        return json.dumps({\"error\": result})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9fa05",
   "metadata": {},
   "source": [
    "# Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8f4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dependencies....\n",
      "Registering the environment...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"MyEnvironment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.33.0\",\n",
       "                        \"joblib\",\n",
       "                        \"numpy\",\n",
       "                        \"azureml-core~=1.33.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"inference-schema[numpy-support]\",\n",
       "                        \"nltk\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"pip\"\n",
       "            ],\n",
       "            \"name\": \"azureml_828b47202a0cea876a9155ae89f42cf8\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"4\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "\n",
    "\n",
    "# Create the environment\n",
    "myenv = Environment(name=\"MyEnvironment\")\n",
    "\n",
    "# Create the dependencies object\n",
    "print(\"Creating dependencies....\")\n",
    "myenv_dep = CondaDependencies.create(conda_packages=['scikit-learn', 'pip'],\n",
    "                                     pip_packages=['azureml-defaults','joblib','numpy','azureml-core', \"azureml-monitoring\", \"inference-schema\", \"inference-schema[numpy-support]\",\"nltk\"])\n",
    "\n",
    "myenv.python.conda_dependencies = myenv_dep\n",
    "\n",
    "# Register the environment\n",
    "print(\"Registering the environment...\")\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c67b9",
   "metadata": {},
   "source": [
    "# Deployment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4800e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(auth_enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94be25",
   "metadata": {},
   "source": [
    "#  Deploy web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "858b6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress..............................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'nlp-aks' \n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (you can also provide parameters to customize this).\n",
    "    # For example, to create a dev/test cluster, use:\n",
    "    # prov_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "    prov_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                    name = aks_name, \n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d026a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(ws, 'NLP_Count_Vectorizer')\n",
    "model2 = Model(ws, 'NLP_RF_Model')\n",
    "\n",
    "service_name = 'nlp-sent-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ddc1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inference_config = InferenceConfig(entry_script='score.py',\n",
    "                                    environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af852088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-22 08:22:10+00:00 Creating Container Registry if not exists.\n",
      "2021-08-22 08:22:10+00:00 Registering the environment.\n",
      "2021-08-22 08:22:14+00:00 Use the existing image..\n",
      "2021-08-22 08:22:16+00:00 Creating resources in AKS.\n",
      "2021-08-22 08:22:17+00:00 Submitting deployment to compute.\n",
      "2021-08-22 08:22:17+00:00 Checking the status of deployment nlp-sent-analysis..\n",
      "2021-08-22 08:24:17+00:00 Checking the status of inference endpoint nlp-sent-analysis.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, service_name, models=[model1, model2], inference_config=inference_config, deployment_config=aks_config, deployment_target=aks_target,overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65f44a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-22T08:24:11,184065623+00:00 - rsyslog/run \n",
      "2021-08-22T08:24:11,184066523+00:00 - iot-server/run \n",
      "2021-08-22T08:24:11,184066523+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2021-08-22T08:24:11,269632566+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-22T08:24:11,351373884+00:00 - iot-server/finish 1 0\n",
      "2021-08-22T08:24:11,352499591+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (15)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-22 08:24:14,015 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-22 08:24:14,015 | root | INFO | Starting up request id generator\n",
      "2021-08-22 08:24:14,015 | root | INFO | Starting up app insight hooks\n",
      "2021-08-22 08:24:14,015 | root | INFO | Invoking user's init function\n",
      "no request id,/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "no request id,/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "no request id,/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "2021-08-22 08:24:14,143 | root | INFO | Users's init has completed successfully\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2021-08-22 08:24:14,145 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-22 08:24:14,145 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-22 08:24:14,146 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-08-22 08:24:18,278 | root | INFO | Swagger file not present\n",
      "2021-08-22 08:24:18,278 | root | INFO | 404\n",
      "127.0.0.1 - - [22/Aug/2021:08:24:18 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.17.4\"\n",
      "2021-08-22 08:24:18,480 | root | INFO | Swagger file not present\n",
      "2021-08-22 08:24:18,480 | root | INFO | 404\n",
      "127.0.0.1 - - [22/Aug/2021:08:24:18 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "2021-08-22 08:24:21,245 | root | INFO | Swagger file not present\n",
      "2021-08-22 08:24:21,245 | root | INFO | 404\n",
      "127.0.0.1 - - [22/Aug/2021:08:24:21 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"hackney/1.17.4\"\n",
      "2021-08-22 08:24:21,705 | root | INFO | Swagger file not present\n",
      "2021-08-22 08:24:21,705 | root | INFO | 404\n",
      "127.0.0.1 - - [22/Aug/2021:08:24:21 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"curl/7.67.0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89d3db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff79e05a",
   "metadata": {},
   "source": [
    "# Test web service "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc738c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://40.89.255.53:80/api/v1/service/nlp-sent-analysis/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21fb0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://40.89.255.53:80/api/v1/service/nlp-sent-analysis/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "793444b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Healthy'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "471e073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [1]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': [[\"I love this phone , It is very handy and has a lot of features .\"]],\n",
    "     # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbe563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
