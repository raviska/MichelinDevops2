{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95be2fd0",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6146e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sn\n",
    "from azureml.core import Workspace, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d87a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "\n",
    "df = pd.read_csv('Dataset/amazonLabelled - amazonLabelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8d1786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback Sentiment\n",
       "0  1                        Good case, Excellent value.  Positive\n",
       "1  2                             Great for the jawbone.  Positive\n",
       "2  3  Tied to charger for conversations lasting more...  Negative\n",
       "3  4                                  The mic is great.  Positive\n",
       "4  5  I have to jiggle the plug to get it to line up...  Negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1f1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29687e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62c31c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    500\n",
       "Negative    499\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5caf6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4201fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cbe3912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.fit(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd152e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentiment\"]=lb.transform(df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51459440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S                                           Feedback  Sentiment\n",
       "0  1                        Good case, Excellent value.          1\n",
       "1  2                             Great for the jawbone.          1\n",
       "2  3  Tied to charger for conversations lasting more...          0\n",
       "3  4                                  The mic is great.          1\n",
       "4  5  I have to jiggle the plug to get it to line up...          0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf48082",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8054c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006e07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(df.drop(\"Sentiment\",axis=1),df[\"Sentiment\"],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529e0bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f0bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.concat([X_train,y_train],axis=1).to_csv(\"Dataset/train_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49fe1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.concat([X_test,y_test],axis=1).to_csv(\"Dataset/test_set.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeff5a3",
   "metadata": {},
   "source": [
    "# Register dataset to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b449b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"29514374-60e8-4ea7-b14f-6778779cf8e4\"\n",
    "resource_group = 'RGDAY5'\n",
    "workspace_name = 'Michelinday5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6cdeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f33a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the datastore to upload prepared data\n",
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9da774fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 3 files\n",
      "Uploading Dataset/amazonLabelled - amazonLabelled.csv\n",
      "Uploaded Dataset/amazonLabelled - amazonLabelled.csv, 1 files out of an estimated total of 3\n",
      "Uploading Dataset/test_set.csv\n",
      "Uploaded Dataset/test_set.csv, 2 files out of an estimated total of 3\n",
      "Uploading Dataset/train_set.csv\n",
      "Uploaded Dataset/train_set.csv, 3 files out of an estimated total of 3\n",
      "Uploaded 3 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_ccdbe7fc35ee49a78480d14ba72e295f"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the local file from src_dir to the target_path in datastore\n",
    "datastore.upload(src_dir='Dataset', target_path='nlpdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc4470e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.Tabular.from_delimited_files(datastore.path('nlpdata/train_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "326142fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset.Tabular.from_delimited_files(datastore.path('nlpdata/test_set.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fe2d37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_dataset.register(workspace=workspace,\n",
    "                                 name='nlp_train_set',\n",
    "                                 description='Training data for nlp usecase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d014f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_dataset.register(workspace=workspace,\n",
    "                                 name='nlp_test_set',\n",
    "                                 description='Test data for nlp usecase')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a87a0",
   "metadata": {},
   "source": [
    "# Data ingestion step - Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d10f61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp_train_set 1\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='nlp_train_set')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9a0666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c030e049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>Also, the phone doesn't seem to accept anythin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214</td>\n",
       "      <td>fast service.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521</td>\n",
       "      <td>Thanks again to Amazon for having the things I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233</td>\n",
       "      <td>Great sound and service.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>I wear it everyday and it holds up very well.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     S                                           Feedback  Sentiment\n",
       "0  700  Also, the phone doesn't seem to accept anythin...          0\n",
       "1  214                                      fast service.          1\n",
       "2  521  Thanks again to Amazon for having the things I...          1\n",
       "3  233                           Great sound and service.          1\n",
       "4   80      I wear it everyday and it holds up very well.          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52f4077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4437f1",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24823b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (2021.7.6)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: joblib in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: click in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from click->nltk) (4.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.10.0.0)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bde9c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6918edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80fb1b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/azureuser/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6705528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ceb47355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    corpus=[]\n",
    "    for i in data:\n",
    "        mess=re.sub(\"[^a-zA-Z0-9]\",\" \",i)\n",
    "        mess=mess.lower().split()\n",
    "        mess=[lemmatizer.lemmatize(word) for word in mess if word not in stopwords.words(\"english\")]\n",
    "        mess=\" \".join(mess)\n",
    "        corpus.append(mess)\n",
    "    return corpus    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0cec76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=preprocess_data(df[\"Feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7f21994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "799"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26997d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b7291f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9acd280b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efb4dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train=cv.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8103771e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 4456)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcf15c8",
   "metadata": {},
   "source": [
    "# Creating experiment and run to log metrics and hypermeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3aa39ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "myexperiment = Experiment(workspace, \"rf_sent_analysis\")\n",
    "# initialize a run in Azureml\n",
    "run = myexperiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "688d2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc9afd",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d83c7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb67ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac9de768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b27dc3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974968710888611"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f781e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "435b5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=cross_val_score(rf,count_train,df[\"Sentiment\"],cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bb721a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722128354594351"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40d79a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026814886955222647"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d61203",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df7e65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "330bcbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'n_estimators': [100, 400,700,1000,2000,2500], 'min_samples_split': [2,4,8,16]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c0832bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(rf,param_grid,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5530171a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'min_samples_split': [2, 4, 8, 16],\n",
       "                         'n_estimators': [100, 400, 700, 1000, 2000, 2500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "56b27ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est=grid.get_params(deep=True)['estimator__n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21db4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sam_splt=grid.get_params(deep=True)['estimator__min_samples_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2450c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=n_est,min_samples_split=min_sam_splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29efd64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(count_train,df[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7611c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"n_estimators\", grid.get_params(deep=True)['estimator__n_estimators'])\n",
    "run.log(\"min_samples_split\", grid.get_params(deep=True)['estimator__min_samples_split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "92c82353",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26714017",
   "metadata": {},
   "source": [
    "# Model Packaging Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6560bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c8f36f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/count_vectorizer.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv,\"outputs/count_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e2cf736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/rf_sent_model.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf,\"outputs/rf_sent_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ba3153e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"tutorial-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-dataset-runtime[pandas,fuse]~=1.33.0\",\n",
       "                        \"numpy\",\n",
       "                        \"joblib\",\n",
       "                        \"azureml-core~=1.33.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"azureml-defaults~=1.33.0\",\n",
       "                        \"scikit-learn==0.20.3\",\n",
       "                        \"inference-schema[numpy-support]\",\n",
       "                        \"nltk-corpus\",\n",
       "                        \"nltk-stem\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn==0.22.1\"\n",
       "            ],\n",
       "            \"name\": \"azureml_b19e1ef3aef06bb6d4d8b4e5a9b725cc\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# to install required packages\n",
    "env = Environment('tutorial-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults',\"numpy\",  \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", \"scikit-learn==0.20.3\", \"inference-schema\", \"inference-schema[numpy-support]\",\"nltk-corpus\",\"nltk-stem\"], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd\n",
    "\n",
    "# Register environment to re-use later\n",
    "env.register(workspace = workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1c3f2",
   "metadata": {},
   "source": [
    "# Model Registering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95602936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "982a6eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model NLP_Count_Vectorizer\n",
      "Name: NLP_Count_Vectorizer\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/count_vectorizer.pkl', # this points to a local file \n",
    "                       model_name = \"NLP_Count_Vectorizer\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, }, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Count Vectorizer\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30c7b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model NLP_RF_Model\n",
      "Name: NLP_RF_Model\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf_sent_model.pkl', # this points to a local file \n",
    "                       model_name = \"NLP_RF_Model\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, }, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random Forest Model\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd60b07",
   "metadata": {},
   "source": [
    "# Deploy model as a webservice on Azure Container Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1141f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import time\n",
    "from azureml.core.model import Model\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def preprocess_data(data):\n",
    "    corpus=[]\n",
    "    for i in data:\n",
    "        mess=re.sub(\"[^a-zA-Z0-9]\",\" \",i)\n",
    "        mess=mess.lower().split()\n",
    "        mess=[lemmatizer.lemmatize(word) for word in mess if word not in stopwords.words(\"english\")]\n",
    "        mess=\" \".join(mess)\n",
    "        corpus.append(mess)\n",
    "    return corpus    \n",
    "\n",
    "\n",
    "def init():\n",
    "    global count_vect,rf_model\n",
    "    \n",
    "    count_vect_path=Model.get_model_path('NLP_Count_Vectorizer')\n",
    "    count_vect= joblib.load(count_vect_path)\n",
    "    \n",
    "    rf_model_path=Model.get_model_path('NLP_RF_Model')\n",
    "    rf_model=joblib.load(rf_model_path)\n",
    "    \n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        corpus=preprocess_data(data[0])\n",
    "        count_test=count_vect.transform(corpus)\n",
    "        prediction=rf_model.predict(count_test)\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return json.dumps({\"result\": prediction.tolist()})\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        # return error message back to the client\n",
    "        return json.dumps({\"error\": result})\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3921226d",
   "metadata": {},
   "source": [
    " # Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "234458a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dependencies....\n",
      "Registering the environment...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"MyEnvironment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.33.0\",\n",
       "                        \"joblib\",\n",
       "                        \"numpy\",\n",
       "                        \"azureml-core~=1.33.0\",\n",
       "                        \"azureml-monitoring\",\n",
       "                        \"inference-schema[numpy-support]\",\n",
       "                        \"nltk\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"pip\"\n",
       "            ],\n",
       "            \"name\": \"azureml_828b47202a0cea876a9155ae89f42cf8\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"2\"\n",
       "}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.environment import CondaDependencies\n",
    "\n",
    "\n",
    "# Create the environment\n",
    "myenv = Environment(name=\"MyEnvironment\")\n",
    "\n",
    "# Create the dependencies object\n",
    "print(\"Creating dependencies....\")\n",
    "myenv_dep = CondaDependencies.create(conda_packages=['scikit-learn', 'pip'],\n",
    "                                     pip_packages=['azureml-defaults','joblib','numpy','azureml-core', \"azureml-monitoring\", \"inference-schema\", \"inference-schema[numpy-support]\",\"nltk\"])\n",
    "\n",
    "myenv.python.conda_dependencies = myenv_dep\n",
    "\n",
    "# Register the environment\n",
    "print(\"Registering the environment...\")\n",
    "myenv.register(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "19b4dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c02d6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script=\"score.py\", environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e0e7c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, collect_model_data=True,auth_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a3190356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(workspace, 'NLP_Count_Vectorizer')\n",
    "model2 = Model(workspace, 'NLP_RF_Model')\n",
    "\n",
    "service_name = 'amazon-feedback-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "06423bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-08-21 10:27:50+00:00 Creating Container Registry if not exists.\n",
      "2021-08-21 10:27:50+00:00 Registering the environment.\n",
      "2021-08-21 10:27:51+00:00 Use the existing image.\n",
      "2021-08-21 10:27:51+00:00 Generating deployment configuration.\n",
      "2021-08-21 10:27:52+00:00 Submitting deployment to compute.\n",
      "2021-08-21 10:27:55+00:00 Checking the status of deployment amazon-feedback-analysis..\n",
      "2021-08-21 10:30:39+00:00 Checking the status of inference endpoint amazon-feedback-analysis.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(workspace, service_name, models=[model1, model2], inference_config=inference_config, deployment_config=deployment_config, overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7f30699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-21T10:30:30,551945300+00:00 - iot-server/run \n",
      "2021-08-21T10:30:30,557946200+00:00 - rsyslog/run \n",
      "2021-08-21T10:30:30,567498500+00:00 - nginx/run \n",
      "2021-08-21T10:30:30,568593300+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-08-21T10:30:30,893731100+00:00 - iot-server/finish 1 0\n",
      "2021-08-21T10:30:30,907116600+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (61)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 86\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-08-21 10:30:35,754 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2021-08-21 10:30:35,760 | root | INFO | Starting up request id generator\n",
      "2021-08-21 10:30:35,760 | root | INFO | Starting up app insight hooks\n",
      "2021-08-21 10:30:35,760 | root | INFO | Invoking user's init function\n",
      "no request id,/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "no request id,/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n",
      "no request id,/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "  UserWarning)\n",
      "\n",
      "2021-08-21 10:30:36,010 | root | INFO | Users's init has completed successfully\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "2021-08-21 10:30:36,017 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-08-21 10:30:36,017 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-08-21 10:30:36,018 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/azureml-envs/azureml_828b47202a0cea876a9155ae89f42cf8/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2021-08-21 10:30:40,676 | root | INFO | Swagger file not present\n",
      "2021-08-21 10:30:40,676 | root | INFO | 404\n",
      "127.0.0.1 - - [21/Aug/2021:10:30:40 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-08-21 10:30:42,089 | root | INFO | Swagger file not present\n",
      "2021-08-21 10:30:42,089 | root | INFO | 404\n",
      "127.0.0.1 - - [21/Aug/2021:10:30:42 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a93d8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1798e7a",
   "metadata": {},
   "source": [
    "# Test web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1c241cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://d023601e-1f80-4ea3-95b2-d54ab79af9d9.centralus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a00e8bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://d023601e-1f80-4ea3-95b2-d54ab79af9d9.centralus.azurecontainer.io/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aa3de0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Healthy'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1885487d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [1]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': [[\"I love this phone , It is very handy and has a lot of features .\"]],\n",
    "     # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9356fbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"{\\\\\"result\\\\\": [1]}\"'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "data = {\n",
    "    'data': [[\"I love this phone , It is very handy and has a lot of features .\"]],\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://d023601e-1f80-4ea3-95b2-d54ab79af9d9.centralus.azurecontainer.io/score'\n",
    "api_key = 'UpKgwdTVPGZC3w8w4ltqRjvMWgvDho4N' # Replace this with the API key for the web service\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3d35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
